Let $(\outcomes, \sigmaAlgebra, \probabilityMeasure)$ be a complete probability space, where $\outcomes$ is a set of outcomes, $\sigmaAlgebra \subseteq 2^\outcomes$ is a $\sigma$-algebra on $\outcomes$, and $\probabilityMeasure: \sigmaAlgebra \to [0, 1]$ is a probability measure \cite{durrett2010}.
A \rv\ on $(\outcomes, \sigmaAlgebra, \probabilityMeasure)$ is an $\sigmaAlgebra$-measurable function $\h: \outcomes \to \real$.
A \rv\ $\h$ is uniquely characterized by its (cumulative) distribution function defined by
\begin{equation*}
  \distribution_\h(\x) := \probabilityMeasure(\{ \o \in \outcomes: \h(\o) \leq \x \}).
\end{equation*}
The expectation and variance of $\h$ are given by
\begin{align*}
  & \expectation{\h} := \int_\outcomes \h(\o) \, \d\probabilityMeasure(\o) = \int_\real \x \, \d \distribution_\h(\x) \hspace{1em} \text{and} \\
  & \variance{\h} := \expectation{(\h - \expectation{\h})^2},
\end{align*}
respectively.
A random vector $\vh = (\h_i)$ and matrix $\mH = (\h_{ij})$ are a vector and matrix whose elements are \rvs.
Let $\L{2}(\outcomes, \sigmaAlgebra, \probabilityMeasure)$ be the Hilbert space of square-integrable \rvs\ \cite{janson1997} defined on $(\outcomes, \sigmaAlgebra, \probabilityMeasure)$ with the inner product and norm defined, respectively, by
\begin{equation*}
  \innerProduct{\h_1, \h_2} := \expectation{\h_1 \h_2} \hspace{1em} \text{and} \hspace{1em} \norm{\h} := \innerProduct{\h, \h}^{1/2}.
\end{equation*}
In what follows, all the \rvs\ will tacitly have $(\outcomes, \sigmaAlgebra, \probabilityMeasure)$ as the underlying probability space.
