Let us fix $\o \in \outcomes$, meaning that $\vu$ is assumed to be known, and consider the system in \eref{thermal-model} as deterministic.
In general, \eref{thermal-model-inner} is a system of ordinary differential equations which is nonlinear due to the power term, given in \eref{power-model} as an arbitrary function.
Hence, the system in \eref{thermal-model} does not have a general closed-form solution.
A robust and computationally efficient solution to \eref{thermal-model} for a given $\vu$ is an essential part of our probabilistic framework.
In order to attain such a solution, we utilize a numerical method from the family of exponential integrators \cite{hochbruck2010}.
The procedure is described in \xref{temperature-solution}, and here we use the final result.

Recall that we are to analyze a dynamic power profile $\mP_\dynamic$ covering a time interval $[0, \period]$ with $\nsteps$ samples that are evenly spaced in time.
The transient solution of \eref{thermal-model-inner} is reduced to the following recurrence for $k = 1, 2, \dots, \nsteps$:
\begin{equation} \elab{recurrence}
  \vs_k = \mE \: \vs_{k - 1} + \mF \: \vp_k
\end{equation}
where the subscript $k$ stands for time $k \dt$, $\vs_0 = \vZero$,
\[
  \mE = e^{\mA \dt}, \hspace{1em} \text{and} \hspace{1em} \mF = \mA^{-1} (e^{\mA \dt} - \mOne) \: \mB.
\]
For computational efficiency, we perform the eigendecomposition of the state matrix $\mA$:
\begin{equation} \elab{eigendecomposition}
  \mA = \mEDV \mEDL \mEDV^T
\end{equation}
where $\mEDV$ and $\mEDL = \diagonal{\lambda_i}$ are an orthogonal matrix of the eigenvectors and a diagonal matrix of the eigenvectors of $\mA$, respectively.
The matrices $\mE$ and $\mF$ are then
\begin{align*}
  & \mE = \mEDV \; \diagonal{e^{\lambda_i \dt}} \mEDV^T \text{ and} \\
  & \mF = \mEDV \; \diagonal{ \frac{e^{\lambda_i \dt} - 1}{\lambda_i} } \mEDV^T \mB.
\end{align*}
To sum up, the derivation up to this point is sufficient for \tta\ via \eref{recurrence} followed by \eref{thermal-model-outer}.
\begin{remark}
Although we refer to temperature, each temperature analysis developed in this paper is accompanied by the corresponding power analysis as the two are inseparable due to the leakage-temperature interplay.
Consequently, when it is appropriate, one can easily extract only the (temperature-aware) power part of the presented solutions.
\end{remark}

Let us move on to the \DSS\ case.
Assume for now that $\vp_\static$ in \eref{power-model} does not depend on $\vq$, \ie, no interdependency between leakage and temperature.
The \DSS\ boundary condition is
\[
  \vs_1 = \vs_{\nsteps + 1}.
\]
In other words, the system is required to come back to its original state by the end of the analyzed time frame.
This constraint and \eref{recurrence} yield a block-circulant system of $\nnodes \nsteps$ linear equations with $\nnodes \nsteps$ unknowns.
As describe in detail in \cite{ukhov2012}, the system can be efficiently solved by exploiting its particular structure and the decomposition in \eref{eigendecomposition}.
The pseudocode of this algorithm, which delivers the exact solution under the above assumptions, is given in \aref{temperature-solution-without-leakage}.
Here we adopt \abbr{MATLAB}'s \cite{matlab} notations $\m{A}(k, :)$ and $\m{A}(:, k)$ to refer to the $k$th row and the $k$th column of a matrix $\m{A}$, respectively.
In the pseudocode, auxiliary variables are written with hats, and $\mQ_\ambient$ is a matrix of the ambient temperature.
\input{include/algorithms/temperature-solution-without-leakage.tex}
\begin{remark}
The time complexity of  direct dense and sparse solvers (\eg, the LU decomposition) of the system of linear equations is $\complexity{\nsteps^3 \nnodes^3}$ while the one of \aref{temperature-solution-without-leakage} is only $\complexity{\nsteps \nnodes^2 + \nnodes^3}$, which the algorithm is able to achieve by exploiting the specific structure of the system; see \cite{ukhov2012}.
\end{remark}

Let us now bring the leakage-temperature interdependence into the picture.
To this end, we repeat \aref{temperature-solution-without-leakage} for a sequence of total power profiles $\{ \mP_k = \mP_\dynamic + \mP_{\static, k} \}$ wherein the static part $\mP_{\static, k}$ is being updated using \eref{power-model} given the temperature profile $\mQ_{k - 1}$ computed at the previous iteration starting from the ambient temperature.
The procedure stops when the sequence of temperature profiles $\{ \mQ_k \}$ converges in an appropriate norm, or some other stopping condition is satisfied (\eg, a maximal temperature constraint is violated).
This procedure is illustrated in \aref{temperature-solution}.
\input{include/algorithms/temperature-solution.tex}

In \aref{temperature-solution}, $\mP_\static(\vu, \mQ)$ should be understood as a call to a subroutine that returns an $\nprocs \times \nsteps$ matrix wherein the $(i, k)$th element is the static component of the power dissipation of the $i$th processing element at the $k$th moment of time with respect to $\vu$ and the temperature given by the $(i, k)$th entry of $\mQ$.

\begin{remark}
A widespread approach to account for leakage is to linearize it with respect to temperature.
As shown in \cite{liu2007}, already one linear segment can deliver sufficiently accurate results.
One notable feature of such a linearization is that no iterating-until-convergence is needed in this case; see \cite{ukhov2012}.
However, this technique assumes that the only varying parameter of leakage is temperature, and all other parameters have nominal values.
In that case, it is relatively easy to decide on a representative temperature range and undertake a one-dimensional curve-fitting procedure with respect to it.
In our case, the power model has multiple parameters stepping far from their nominal values, which makes it difficult to construct a good linear fit with respect to temperature.
\end{remark}

So far in this subsection, $\vu$ was assumed to be deterministic.
Now we turn to the stochastic scenario and let $\vu$ be random again.
Then we apply \aref{surrogate-construction} to one particular quantity of interest $\w$.
Specifically, $\w$ is now the temperature profile $\mQ$ corresponding to a given $\mP_\dynamic$.
Since $\mQ$ is an $\nprocs \times \nsteps$ matrix, following \rref{multiple-dimensions}, $\w$ is viewed as an $\nprocs \nsteps$-element row vector, in which case each coefficient $\coefficient{\w}_{\multiindex}$ in \eref{spectral-decomposition} is also such a vector.
Then the projection in \eref{coefficient-evaluation} and, consequently, \aref{surrogate-construction} should be interpreted as follows.
$\evw$ is an $\nqorder \times \nprocs \nsteps$ matrix, and the $i$th row of this matrix is the temperature profile computed at the $i$th quadrature point and reshaped into a row vector.
Similarly, $\coefficient{\evw}$ is an $\ncorder \times \nprocs \nsteps$ matrix, and the $i$th row of this matrix is the $i$th coefficient $\coefficient{\w}_{\multiindex_i}$ of the spectral decomposition in \eref{spectral-decomposition} (recall that a fixed ordering is assumed to be imposed on the multi-indices).
Keeping the above in mind, a call to \aref{surrogate-construction} should be made such that Algorithm~X points at an auxiliary routine which receives $\vu$, forwards it to \aref{temperature-solution} along with $\mP_\dynamic$, and returns the resulting temperature profile to \aref{surrogate-construction}.
Now the constructed expansion can be post-processed as needed; see \sref{post-processing}.

To give a concrete example, for a dual-core system ($\nprocs = 2$) with one independent random variable ($\nvars = 1$), a second-level expansion ($\nclevel = 2$) of the temperature profile with 100 time steps ($\nsteps = 100$) can be written as follows (see \eref{spectral-decomposition}):
\[
  \w \approx \coefficient{\w}_0 + \coefficient{\w}_1 \z + \coefficient{\w}_2(\z^2 - 1),
\]
which is a polynomial in $\z$, and each coefficient is a vector with $\nprocs \nsteps = 200$ elements.
Then, for any outcome $\z \equiv \z(\o)$, the corresponding temperature profile $\mQ$ can be evaluated by plugging in $\z$ into the above equation and reshaping the result into an $\nprocs \times \nsteps = 2 \times 100$ matrix.
In this case, the three rows of $\coefficient{\evw}$ are $\coefficient{\w}_0$, $\coefficient{\w}_1$, and $\coefficient{\w}_2$; the first one is also a flattened version of the expected value of $\mQ$ as shown in \eref{probabilistic-moments}.
