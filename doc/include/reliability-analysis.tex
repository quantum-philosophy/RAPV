Let $\T: \outcomes \to \real$ be a \rv\ representing the lifetime of the considered system.
The lifetime is the time until the system experiences a fault after which the system no longer meets the requirements imposed on this system.
Let $\distribution_\T(\cdot | \vwr)$ be the distribution of $\T$ where $\vwr = (\wr_i)$ is a vector of parameters.
The survival function of the system is
\[
  \survival_\T(\t | \vwr) = 1 - \distribution_\T(\t | \vwr).
\]

The overall lifetime $\T$ is a function of the lifetimes of the processing elements, which are denoted by a set of \rvs\ $\{ \T_i \}_{i = 1}^\nprocs$.
Each $\T_i$ is characterized by a physical model of wear \cite{jedec2011} describing the fatigues that the corresponding processing element is suffering from.
Each $\T_i$ is also assigned an individual survival function $\survival_{\T_i}(\cdot, \vwr)$ describing the rate of failures due to those fatigues.
The structure of $\survival_\T(\cdot, \vwr)$ with respect to $\{ \survival_{\T_i}(\cdot, \vwr) \}_{i = 1}^\nprocs$ is problem specific, and it can be especially diverse in the context of fault-tolerant systems.
Thus, $\survival_\T(\cdot, \vwr)$ along with the corresponding parametrization $\vwr$ are to be specified by the designer of the system.

\subsection{Problems and Our Solution}
In this context, our primary objective is to build a flexible and computationally efficient framework for the reliability analysis of electronic systems deteriorated by process variation.
Our work is motivated by the following two observations.

First, temperature is the driving force of the dominant failure mechanisms.
The most prominent examples include electromigration, time-dependent dielectric breakdown, stress migration, and thermal cycling \cite{xiang2010}; see \cite{jedec2011} for an exhaustive overview.
All of the aforementioned mechanisms have exponentially dependencies on the operating temperature.
At the same time, temperature is tightly related to process parameters, such as the effective channel length and gate-oxide thickness, and can vary dramatically when those parameters deviate from their nominal values \cite{ukhov2014, juan2012}.
Meanwhile, the state-of-the-art techniques for reliability analysis of electronic systems lack a systematic treatment of process variation and, in particular, of the effect of process variation on temperature.

Second, having determined a probabilistic model $\survival_\T(\cdot, \vwr)$ of the considered system, the major portion of the associated computational time is ascribed to the evaluation of the parametrization $\vwr$ rather than to the model \perse, that is, when $\vwr$ is known.
For instance, $\vwr$ often contains estimates of the mean time to failure of each processing element given for a range of stress levels.
Therefore, $\vwr$ typically involves (computationally intensive) full-system simulations including power analysis paired with temperature analysis \cite{xiang2010}.

Guided by the two observations mentioned earlier, we propose to the use of the spectral decompositions developed in \sref{uncertainty-analysis} and \sref{temperature-analysis} in order to construct a light surrogate for $\vwr$.
The proposed technique is founded on the basis of the state-of-the-art reliability models by enriching their modeling capabilities with respect to process variation and by speeding up the associated computational process.
This approach allows one to seamlessly incorporate into reliability analysis the effect of process variation on process parameters.
In particular, the framework allows for a straightforward propagation of the uncertainty from process parameters through power and temperature to the lifetime of the system.
In contrast to the straightforward use of MC sampling, the spectral representation that we construct makes the subsequent analysis highly efficient from the computational perspective.

It is worth noting that $\survival_\T(\cdot, \vwr)$ is left intact, meaning that our approach does not impose any restrictions on $\survival_\T(\cdot, \vwr)$ and, thus, is readily applicable to any model that the user considers to be the most adequate for the problem at hand.

Despite its generality, the proposed technique can be better appreciated considering a concrete example.
To this end, we assume that any fault of any processing element makes the system fail, and $\{ \T_i \}_{i = 1}^\nprocs$ are conditionally independent given the parameters gathered in $\vwr$.
In this scenario,
\[
  \T = \min_{i = 1}^\nprocs \T_i \hspace{1em} \text{and} \hspace{1em} \survival_\T(\t | \vwr) = \prod_{i = 1}^\nprocs \survival_{\T_i}(\t, \vwr).
\]

Next, suppose that the system is experiencing a periodic workload (\eg, due to the execution of a periodic application) with period $\period$.
Assume further that the power consumption is rapidly changing during $\period$, and, thus, the major concern of the designer is the thermal-cycling fatigue \cite{jedec2011}.
This fatigue has the most prominent dependency on temperature: apart from average/maximal temperatures, the frequencies and amplitudes of temperature fluctuations matter in this case.
Therefore, the knowledge of the temperature profile $\mQ$ of the system under the given workload is required.
Since the assumed workload is periodic, $\mQ$ is a \dss\ temperature profile over a time interval of length $\period$.
Then, for a given $\vu$, $\mQ$ is computed using \aref{temperature-solution}.

The failures due to the thermal-cycling fatigue are modeled using Weibull distributions \cite{ukhov2012, xiang2010}.
In this case,
\[
  \ln \survival_{\T_i}(\t, \vwr) = -\left( \frac{\t}{\eta_i} \right)^{\beta_i}
\]
where $\eta_i$ and $\beta_i$ are called the scale and shape parameters of the distribution, respectively.
Both $\eta_i$ and $\beta_i$ are affected by process variation, and the impact of temperature is significant only with respect to the scale parameter $\eta_i$.

The information in $\vwr$ is used to determine $\eta_i$ and $\beta_i$.
The $i$th row of this matrix, denoted by $\mQ(i, :)$, is the temperature curve of the $i$th processing element.
Each $\mQ(i, :)$ is analyzed using a peak-detection algorithm in order to extract the extrama of this curve.
The scale parameter is given as follows:
\[
  \eta_i = \frac{\sum_j \dt_{ij}}{\sum_j\frac{ \dt_{ij}}{\eta_{ij}}}
\]
