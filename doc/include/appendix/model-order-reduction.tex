In this section, we discuss the model order reduction procedure performed by $\transformation$ in \sref{parameter-preprocessing}.
Let $\mCov_\z$ be the covariance matrix of the standardized random vector $\vz$ (which is the result of the first step of the Nataf transformation outlined in \xref{probability-transformation}).
Since any covariance matrix is real and symmetric, $\mCov_\z$ admits the eigenvalue decomposition as $\mCov_\z = \mV \mL \mV^T$ (see \sref{thermal-model} for the notation).
$\vz$ can then be represented as $\vz = \mV \mL^\frac{1}{2} \vz$ where the vector $\vz$ is standardized and uncorrelated, which is also independent as $\vz$ is Gaussian.

The decomposition above provides means for model order reduction.
The intuition is that, due to the correlations possessed by $\vz \in \real^{\nparams \nprocs}$, it can be recovered from a small subset $\vz \in \real^\nvars$ of $\vz\in \real^{\nparams \nprocs}$, $\nvars \ll \nparams \nprocs$.
Such redundancies can be revealed by analyzing the eigenvalues $\dimensionContribution = (\lambda_i)_{i = 1}^{\nparams \nprocs}$ located on the diagonal of $\mL$, which are all non-negative.
Without loss of generality, we let $\lambda_i \geq \lambda_j$ whenever $i < j$ and assume $\norm[1]{\dimensionContribution} = 1$.
Then we can identify the smallest $\nvars$ such that $\sum_{i = 1}^\nvars \lambda_i$ is greater than a certain threshold chosen from the interval $(0, 1]$.
When this threshold is sufficiently high (close to one), the rest of the eigenvalues and the corresponding eigenvectors can be dropped as being insignificant, reducing the number of stochastic dimensions to $\nvars$.
